{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\aman7\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aman7\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (1.26.3)\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\n",
      "  Downloading pyarrow-15.0.2-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.2-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting requests>=2.19.0 (from datasets)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.62.1 (from datasets)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in c:\\users\\aman7\\appdata\\roaming\\python\\python310\\site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2023.4.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\aman7\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aman7\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (6.0.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl.metadata (32 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
      "  Downloading huggingface_hub-0.22.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.22.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.21.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.21.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fsspec[http]<=2024.3.1,>=2023.1.0 (from datasets)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aman7\\.conda\\envs\\gpu_env\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.19.0->datasets)\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.19.0->datasets)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.19.0->datasets)\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.19.0->datasets)\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\aman7\\.conda\\envs\\gpu_env\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aman7\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aman7\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
      "   ---------------------------------------- 0.0/542.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/542.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/542.0 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 41.0/542.0 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 41.0/542.0 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 112.6/542.0 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 327.7/542.0 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 542.0/542.0 kB 2.6 MB/s eta 0:00:00\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "   ---------------------------------------- 0.0/172.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 172.0/172.0 kB ? eta 0:00:00\n",
      "Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "   ---------------------------------------- 0.0/388.9 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 317.4/388.9 kB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 388.9/388.9 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.5-cp310-cp310-win_amd64.whl (370 kB)\n",
      "   ---------------------------------------- 0.0/370.7 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 30.7/370.7 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 30.7/370.7 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 122.9/370.7 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 122.9/370.7 kB 1.4 MB/s eta 0:00:01\n",
      "   ----------------- -------------------- 174.1/370.7 kB 871.5 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 174.1/370.7 kB 871.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 370.7/370.7 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading pyarrow-15.0.2-cp310-cp310-win_amd64.whl (24.8 MB)\n",
      "   ---------------------------------------- 0.0/24.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/24.8 MB 9.8 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.0/24.8 MB 12.2 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.0/24.8 MB 12.2 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.0/24.8 MB 12.2 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.0/24.8 MB 5.5 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.0/24.8 MB 5.5 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.1/24.8 MB 3.8 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 1.1/24.8 MB 3.8 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 1.2/24.8 MB 3.0 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.2/24.8 MB 3.0 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.4/24.8 MB 2.6 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.8/24.8 MB 3.3 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.4/24.8 MB 3.9 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.7/24.8 MB 4.3 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.7/24.8 MB 4.3 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.8/24.8 MB 3.9 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.8/24.8 MB 3.9 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.8/24.8 MB 3.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.8/24.8 MB 3.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.9/24.8 MB 3.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.9/24.8 MB 3.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.9/24.8 MB 3.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 3.0/24.8 MB 2.9 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 3.4/24.8 MB 3.1 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 3.9/24.8 MB 3.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.3/24.8 MB 3.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.4/24.8 MB 3.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.5/24.8 MB 3.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.5/24.8 MB 3.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.6/24.8 MB 3.5 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.6/24.8 MB 3.5 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.7/24.8 MB 3.3 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 4.7/24.8 MB 3.3 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 4.7/24.8 MB 3.3 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 4.8/24.8 MB 3.1 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 4.9/24.8 MB 3.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 5.2/24.8 MB 3.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 5.8/24.8 MB 3.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 6.2/24.8 MB 3.6 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.5/24.8 MB 3.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.5/24.8 MB 3.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.6/24.8 MB 3.6 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.6/24.8 MB 3.6 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.6/24.8 MB 3.6 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.7/24.8 MB 3.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.7/24.8 MB 3.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.8/24.8 MB 3.3 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.8/24.8 MB 3.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 6.8/24.8 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 7.0/24.8 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 7.3/24.8 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 7.7/24.8 MB 3.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.1/24.8 MB 3.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.1/24.8 MB 3.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.2/24.8 MB 3.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.2/24.8 MB 3.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.3/24.8 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.3/24.8 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.3/24.8 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.3/24.8 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 8.3/24.8 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 8.4/24.8 MB 3.2 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 8.7/24.8 MB 3.2 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 9.3/24.8 MB 3.4 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 9.8/24.8 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.0/24.8 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.1/24.8 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.1/24.8 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.1/24.8 MB 3.4 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.1/24.8 MB 3.4 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.1/24.8 MB 3.4 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.2/24.8 MB 3.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.2/24.8 MB 3.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.3/24.8 MB 3.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.3/24.8 MB 3.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.7/24.8 MB 3.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 11.1/24.8 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 11.5/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.8/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.8/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.8/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 11.9/24.8 MB 3.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 11.9/24.8 MB 3.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.0/24.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.0/24.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.1/24.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.1/24.8 MB 3.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.5/24.8 MB 3.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.1/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.7/24.8 MB 3.7 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.8/24.8 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.8/24.8 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.9/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.9/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.9/24.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.9/24.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 14.0/24.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 14.0/24.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 14.1/24.8 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.4/24.8 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 14.9/24.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.3/24.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.3/24.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.4/24.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.4/24.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.5/24.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.5/24.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.5/24.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.5/24.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.5/24.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.7/24.8 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.3/24.8 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.9/24.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.4/24.8 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.5/24.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.5/24.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.5/24.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.6/24.8 MB 3.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.6/24.8 MB 3.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.7/24.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.7/24.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.8/24.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.8/24.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 18.0/24.8 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 18.5/24.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.0/24.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.3/24.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.3/24.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.4/24.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.4/24.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.4/24.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.5/24.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.5/24.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.5/24.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.6/24.8 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.6/24.8 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.8/24.8 MB 3.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.4/24.8 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.8/24.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.1/24.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.1/24.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.2/24.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.2/24.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.3/24.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.3/24.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.3/24.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.3/24.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.4/24.8 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.6/24.8 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 21.9/24.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.4/24.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.8/24.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.9/24.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.9/24.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.9/24.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.0/24.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.0/24.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.1/24.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.1/24.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.2/24.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.3/24.8 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.8/24.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.8/24.8 MB 3.6 MB/s eta 0:00:00\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 41.0/78.3 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 41.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 724.0 kB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "   ---------------------------------------- 0.0/134.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/134.8 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 81.9/134.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 134.8/134.8 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading pandas-2.2.2-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/11.6 MB 11.6 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.7/11.6 MB 9.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/11.6 MB 10.8 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.0/11.6 MB 10.8 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.1/11.6 MB 5.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.1/11.6 MB 5.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.1/11.6 MB 5.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.2/11.6 MB 4.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.2/11.6 MB 4.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 3.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 3.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.4/11.6 MB 2.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.7/11.6 MB 3.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.2/11.6 MB 3.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.7/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.8/11.6 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/11.6 MB 4.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/11.6 MB 4.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/11.6 MB 4.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.0/11.6 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.0/11.6 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.0/11.6 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.0/11.6 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.0/11.6 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.2/11.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.6/11.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.0/11.6 MB 3.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.4/11.6 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.6/11.6 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.6/11.6 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.6/11.6 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.7/11.6 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.7/11.6 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.7/11.6 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.8/11.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.8/11.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.9/11.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.9/11.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.2/11.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.7/11.6 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.3/11.6 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.6/11.6 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.6/11.6 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.7/11.6 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.7/11.6 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.7/11.6 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.0/11.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.4/11.6 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.8/11.6 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.1/11.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.1/11.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.2/11.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.2/11.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.3/11.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.3/11.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.3/11.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.4/11.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.4/11.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.5/11.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.6/11.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.2/11.6 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.2/11.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.3/11.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.3/11.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.3/11.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.3/11.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.3/11.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.4/11.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.4/11.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.4/11.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.7/11.6 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.2/11.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 3.6 MB/s eta 0:00:00\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "   ---------------------------------------- 0.0/163.8 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 61.4/163.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 163.8/163.8 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.3/100.3 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.4/50.4 kB ? eta 0:00:00\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.8/66.8 kB ? eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "   ---------------------------------------- 0.0/505.5 kB ? eta -:--:--\n",
      "   ------------------ -------------------- 235.5/505.5 kB 15.0 MB/s eta 0:00:01\n",
      "   ------------------ -------------------- 235.5/505.5 kB 15.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 317.4/505.5 kB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 317.4/505.5 kB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 419.8/505.5 kB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 419.8/505.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  501.8/505.5 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 505.5/505.5 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 256.0/345.4 kB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 345.4/345.4 kB 7.1 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 121.1/121.1 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.4/76.4 kB 4.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, tqdm, pyarrow-hotfix, pyarrow, multidict, idna, fsspec, frozenlist, dill, charset-normalizer, certifi, attrs, async-timeout, yarl, requests, pandas, multiprocess, aiosignal, huggingface-hub, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.2.0 certifi-2024.2.2 charset-normalizer-3.3.2 datasets-2.19.0 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.3.1 huggingface-hub-0.22.2 idna-3.7 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.2 pyarrow-15.0.2 pyarrow-hotfix-0.6 pytz-2024.1 requests-2.31.0 tqdm-4.66.2 tzdata-2024.1 urllib3-2.2.1 xxhash-3.4.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anyio 4.3.0 requires exceptiongroup>=1.0.2; python_version < \"3.11\", which is not installed.\n",
      "anyio 4.3.0 requires sniffio>=1.1, which is not installed.\n",
      "httpcore 1.0.5 requires h11<0.15,>=0.13, which is not installed.\n",
      "httpx 0.27.0 requires sniffio, which is not installed.\n",
      "jupyter-server 2.14.0 requires jinja2>=3.0.3, which is not installed.\n",
      "jupyterlab 4.1.6 requires jinja2>=3.0.3, which is not installed.\n",
      "jupyterlab-server 2.26.0 requires jinja2>=3.0.3, which is not installed.\n",
      "jupyterlab-server 2.26.0 requires json5>=0.9.0, which is not installed.\n",
      "nbformat 5.10.4 requires fastjsonschema>=2.15, which is not installed.\n",
      "torch 2.2.2+cu121 requires jinja2, which is not installed.\n",
      "torch 2.2.2+cu121 requires sympy, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "     ---------------------------------------- 0.0/137.6 kB ? eta -:--:--\n",
      "     ----------- --------------------------- 41.0/137.6 kB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 137.6/137.6 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\aman7\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\aman7\\.conda\\envs\\gpu_env\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aman7\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aman7\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aman7\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.4.16-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\aman7\\.conda\\envs\\gpu_env\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aman7\\.conda\\envs\\gpu_env\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aman7\\.conda\\envs\\gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aman7\\.conda\\envs\\gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aman7\\.conda\\envs\\gpu_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aman7\\.conda\\envs\\gpu_env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aman7\\.conda\\envs\\gpu_env\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aman7\\.conda\\envs\\gpu_env\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aman7\\.conda\\envs\\gpu_env\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "   ---------------------------------------- 0.0/9.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.0 MB 7.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.7/9.0 MB 8.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.7/9.0 MB 8.3 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.7/9.0 MB 4.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.7/9.0 MB 4.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.7/9.0 MB 4.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.8/9.0 MB 3.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.8/9.0 MB 3.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.8/9.0 MB 2.2 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.8/9.0 MB 2.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/9.0 MB 2.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.6/9.0 MB 2.9 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.1/9.0 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.3/9.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.3/9.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.4/9.0 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.4/9.0 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.5/9.0 MB 3.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.5/9.0 MB 3.1 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.6/9.0 MB 2.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.6/9.0 MB 2.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.6/9.0 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.8/9.0 MB 2.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.5/9.0 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.0/9.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.5/9.0 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.6/9.0 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.6/9.0 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.6/9.0 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.7/9.0 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.7/9.0 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.7/9.0 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.7/9.0 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.8/9.0 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.9/9.0 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.4/9.0 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.0/9.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.6/9.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.6/9.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.6/9.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.7/9.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.7/9.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.8/9.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.8/9.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.8/9.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.9/9.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.0/9.0 MB 3.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.5/9.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.1/9.0 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.7/9.0 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.7/9.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/9.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/9.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/9.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.0/9.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.0/9.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.0/9.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.0/9.0 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading regex-2024.4.16-cp310-cp310-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 268.9/268.9 kB 17.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp310-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 287.4/287.4 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 12.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.2 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.2 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.8/2.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.8/2.2 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.9/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.9/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.9/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.4.16 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.40.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U datasets\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACE_API_KEY']='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"knkarthick/dialogsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "    num_rows: 12460\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INput dialogue \n",
      " #Person1#: Happy Birthday, this is for you, Brian.\n",
      "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
      "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
      "#Person2#: Ok.\n",
      "#Person1#: This is really wonderful party.\n",
      "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
      "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
      "#Person2#: You look great, you are absolutely glowing.\n",
      "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
      "INput summary \n",
      " #Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INput dialogue \n",
      " #Person1#: Happy Birthday, this is for you, Brian.\n",
      "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
      "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
      "#Person2#: Ok.\n",
      "#Person1#: This is really wonderful party.\n",
      "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
      "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
      "#Person2#: You look great, you are absolutely glowing.\n",
      "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
      "INput summary \n",
      " #Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num=[10,40]\n",
    "line='-'.join('' for x in range(100))\n",
    "for i in num:\n",
    "  print(line)\n",
    "  print(f\"INput dialogue \\n {dataset['test'][num]['dialogue'][0]}\")\n",
    "  print(f\"INput summary \\n {dataset['test'][num]['summary'][0]}\")\n",
    "  print(line)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spiece.model: 100%|| 792k/792k [00:00<00:00, 11.6MB/s]\n",
      "tokenizer.json: 100%|| 2.42M/2.42M [00:01<00:00, 1.81MB/s]\n",
      "special_tokens_map.json: 100%|| 2.20k/2.20k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 363,   97,   19,   34,    6, 3059,   58,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tensor([ 363,   97,   19,   34,    6, 3059,   58,    1])\n",
      "What time is it, Tom?\n"
     ]
    }
   ],
   "source": [
    "sentence = \"What time is it, Tom?\"\n",
    "\n",
    "sent_encode=tokenizer(sentence,return_tensors='pt')\n",
    "print(sent_encode)\n",
    "print(sent_encode['input_ids'][0])\n",
    "sentence_decoded = tokenizer.decode(\n",
    "        sent_encode[\"input_ids\"][0], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "print(sentence_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "dialogue \n",
      " #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "human summary \n",
      " #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "generated: \n",
      " Person1: It's ten to nine.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "dialogue \n",
      " #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "human summary \n",
      " #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "generated: \n",
      " #Person1#: I'm thinking of upgrading my computer.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num=[40,200]\n",
    "line='-'.join('' for x in range(100))\n",
    "for i in num:\n",
    "  print(line)\n",
    "  dialogue=dataset['test'][i]['dialogue']\n",
    "  summary=dataset['test'][i]['summary']\n",
    "  print(f\"dialogue \\n {dialogue}\")\n",
    "  print(f\"human summary \\n {summary}\")\n",
    "  # print(line)\n",
    "  inputs=tokenizer(dialogue,return_tensors='pt')\n",
    "  output=tokenizer.decode(model.generate(inputs['input_ids'],\n",
    "                        max_new_tokens=50,\n",
    "                        )[0],\n",
    "                        skip_special_tokens=True)\n",
    "  \n",
    "  print(f'generated: \\n {output}')\n",
    "  print(line)\n",
    "  print()\n",
    "  \n",
    "## next sentence makeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## give some prompt \n",
    "\n",
    "#### zero shot inference with instruction prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "dialogue \n",
      " #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "human summary \n",
      " #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "\n",
      "Prompt genrated:\n",
      "\n",
      "  Summarize the following conversation:\n",
      "  #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there. \n",
      "\n",
      "  Summary:\n",
      "  \n",
      "zero shot inference generated: \n",
      " The train is about to leave.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "dialogue \n",
      " #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "human summary \n",
      " #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "\n",
      "Prompt genrated:\n",
      "\n",
      "  Summarize the following conversation:\n",
      "  #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks. \n",
      "\n",
      "  Summary:\n",
      "  \n",
      "zero shot inference generated: \n",
      " #Person1#: You'd probably want to upgrade your computer. #Person2#: You could also upgrade your hardware. #Person1#: You'd probably want a faster processor, more memory and a\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def zero_shot_inference(dialogue):\n",
    "  return f\"\"\"\n",
    "  Summarize the following conversation:\n",
    "  {dialogue} \n",
    "\n",
    "  Summary:\n",
    "  \"\"\"\n",
    "\n",
    "num=[40,200]\n",
    "line='-'.join('' for x in range(100))\n",
    "for i in num:\n",
    "  print(line)\n",
    "  dialogue=dataset['test'][i]['dialogue']\n",
    "  summary=dataset['test'][i]['summary']\n",
    "  print(f\"dialogue \\n {dialogue}\")\n",
    "  print(f\"human summary \\n {summary}\")\n",
    "  print()\n",
    "  print(f'Prompt genrated:\\n{zero_shot_inference(dialogue)}')\n",
    "  # print(line)\n",
    "  inputs=tokenizer(zero_shot_inference(dialogue),return_tensors='pt')\n",
    "  output=tokenizer.decode(model.generate(inputs['input_ids'],\n",
    "                        max_new_tokens=50,\n",
    "                        )[0],\n",
    "                        skip_special_tokens=True)\n",
    "  \n",
    "  print(f'zero shot inference generated: \\n {output}')\n",
    "  print(line)\n",
    "  print()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "dialogue \n",
      " #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "human summary \n",
      " #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "\n",
      "Prompt genrated:\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "#Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "\n",
      "What was going on?\n",
      "  \n",
      "zero shot inference generated: \n",
      " Tom is late for the train.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "dialogue \n",
      " #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "human summary \n",
      " #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "\n",
      "Prompt genrated:\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "\n",
      "What was going on?\n",
      "  \n",
      "zero shot inference generated: \n",
      " #Person1#: You could add a painting program to your software. #Person2#: That would be a bonus. #Person1#: You might also want to upgrade your hardware. #Person1#\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def zero_shot_inference_flan(dialogue):\n",
    "  return f\"\"\"\n",
    "Dialogue:\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "What was going on?\n",
    "  \"\"\"\n",
    "\n",
    "num=[40,200]\n",
    "line='-'.join('' for x in range(100))\n",
    "for i in num:\n",
    "  print(line)\n",
    "  dialogue=dataset['test'][i]['dialogue']\n",
    "  summary=dataset['test'][i]['summary']\n",
    "  print(f\"dialogue \\n {dialogue}\")\n",
    "  print(f\"human summary \\n {summary}\")\n",
    "  print()\n",
    "  print(f'Prompt genrated:\\n{zero_shot_inference_flan(dialogue)}')\n",
    "  # print(line)\n",
    "  inputs=tokenizer(zero_shot_inference_flan(dialogue),return_tensors='pt')\n",
    "  output=tokenizer.decode(model.generate(inputs['input_ids'],\n",
    "                        max_new_tokens=50,\n",
    "                        )[0],\n",
    "                        skip_special_tokens=True)\n",
    "  \n",
    "  print(f'zero shot inference flan generated: \\n {output}')\n",
    "  print(line)\n",
    "  print()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "dialogue \n",
      " #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "human summary \n",
      " #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "\n",
      "Prompt genrated:\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "#Person1#: How do you put this seat back? I know there is a lever somewhere.\n",
      "#Person2#: What are you doing?\n",
      "#Person1#: I'm getting dressed, what does it look like?\n",
      "#Person2#: It looks like you are about to get dressed. Did you forget we are in a car on the road?\n",
      "#Person1#: I'm good at this. Nobody will see anything.\n",
      "#Person2#: Are you kidding? You're going to cause an accident just from people gawking!\n",
      "#Person1#: All right, pull over at that service station and I'll dress in the ladies'room.\n",
      "#Person2#: That will be my pleasure.\n",
      "\n",
      "What was going on?\n",
      "#Person1#'s getting dressed in the car, and #Person2# warns her not. #Person1#'ll get dressed at the service station.\n",
      "\n",
      "    \n",
      "Dialogue:\n",
      "\n",
      "#Person1#: We're supposed to check in at the Air China's counter 30 minutes before take-off, Joe.\n",
      "#Person2#: Yes, I know. The boarding time on the ticket says 17:05, and now it's 16:15. I guess we have plenty of time.\n",
      "#Person1#: Do we need to show our ID cards when checking in?\n",
      "#Person2#: Yes. It's essential.\n",
      "#Person1#: What about our luggage?\n",
      "#Person2#: We can check it and hand carry the small bags. And we have to open each for inspection.\n",
      "#Person1#: Are they going to frisk all the passengers?\n",
      "#Person2#: I think so. We certainly don't want a hijack to happen on the plane today.\n",
      "\n",
      "What was going on?\n",
      "#Person1# asks #Person2# what they need to do when they check in at the Air China's counter.\n",
      "\n",
      "    \n",
      "Dialogue:\n",
      "\n",
      "#Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "\n",
      "What was going on?\n",
      "\n",
      "few shot inference generated: \n",
      " Tom is late. He has to catch the nine-thirty train.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "dialogue \n",
      " #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "human summary \n",
      " #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "\n",
      "Prompt genrated:\n",
      "\n",
      "Dialogue:\n",
      "\n",
      "#Person1#: How do you put this seat back? I know there is a lever somewhere.\n",
      "#Person2#: What are you doing?\n",
      "#Person1#: I'm getting dressed, what does it look like?\n",
      "#Person2#: It looks like you are about to get dressed. Did you forget we are in a car on the road?\n",
      "#Person1#: I'm good at this. Nobody will see anything.\n",
      "#Person2#: Are you kidding? You're going to cause an accident just from people gawking!\n",
      "#Person1#: All right, pull over at that service station and I'll dress in the ladies'room.\n",
      "#Person2#: That will be my pleasure.\n",
      "\n",
      "What was going on?\n",
      "#Person1#'s getting dressed in the car, and #Person2# warns her not. #Person1#'ll get dressed at the service station.\n",
      "\n",
      "    \n",
      "Dialogue:\n",
      "\n",
      "#Person1#: We're supposed to check in at the Air China's counter 30 minutes before take-off, Joe.\n",
      "#Person2#: Yes, I know. The boarding time on the ticket says 17:05, and now it's 16:15. I guess we have plenty of time.\n",
      "#Person1#: Do we need to show our ID cards when checking in?\n",
      "#Person2#: Yes. It's essential.\n",
      "#Person1#: What about our luggage?\n",
      "#Person2#: We can check it and hand carry the small bags. And we have to open each for inspection.\n",
      "#Person1#: Are they going to frisk all the passengers?\n",
      "#Person2#: I think so. We certainly don't want a hijack to happen on the plane today.\n",
      "\n",
      "What was going on?\n",
      "#Person1# asks #Person2# what they need to do when they check in at the Air China's counter.\n",
      "\n",
      "    \n",
      "Dialogue:\n",
      "\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "\n",
      "What was going on?\n",
      "\n",
      "few shot inference generated: \n",
      " #Person1 recommends upgrading their system and hardware.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def few_shot_inference_flan(example_ind,dialogue):\n",
    "  prompt=''\n",
    "  for i in example_ind:\n",
    "    dial=dataset['train'][i]['dialogue']\n",
    "    summ=dataset['train'][i]['summary']\n",
    "    prompt+=f'''\n",
    "Dialogue:\n",
    "\n",
    "{dial}\n",
    "\n",
    "What was going on?\n",
    "{summ}\n",
    "\n",
    "    '''\n",
    "  prompt+=f'''\n",
    "Dialogue:\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "What was going on?\n",
    "'''\n",
    "  return prompt\n",
    "\n",
    "num=[40,200]\n",
    "line='-'.join('' for x in range(100))\n",
    "for i in num:\n",
    "  print(line)\n",
    "  dialogue=dataset['test'][i]['dialogue']\n",
    "  summary=dataset['test'][i]['summary']\n",
    "  print(f\"dialogue \\n {dialogue}\")\n",
    "  print(f\"human summary \\n {summary}\")\n",
    "  print()\n",
    "  print(f'Prompt genrated:\\n{few_shot_inference_flan([20,21],dialogue)}')\n",
    "  # print(line)\n",
    "  inputs=tokenizer(few_shot_inference_flan([19,21],dialogue),return_tensors='pt')\n",
    "  output=tokenizer.decode(model.generate(inputs['input_ids'],\n",
    "                        generation_config = GenerationConfig(max_new_tokens=60, do_sample=True, temperature=0.2)\n",
    "                        )[0],\n",
    "                        skip_special_tokens=True)\n",
    "  \n",
    "  print(f'few shot inference generated: \\n {output}')\n",
    "  print(line)\n",
    "  print()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results are better with the few shot than one shot and zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation_config = GenerationConfig(max_new_tokens=50)\n",
    "# generation_config = GenerationConfig(max_new_tokens=10)\n",
    "# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1)\n",
    "# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.5)\n",
    "generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0)\n",
    "\n",
    "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        generation_config=generation_config,\n",
    "    )[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
